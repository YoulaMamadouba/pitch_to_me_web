'use client';

import React, { useEffect, useRef, useState, useCallback } from 'react';
import { Camera, CameraOff, Play, Square, Eye, TrendingUp, Hand, Target, AlertCircle, Brain, Loader2 } from 'lucide-react';
import { MEDIAPIPE_CONFIG, calculateConfidenceScore, getScoreColor, getScoreBarColor } from '@/lib/mediapipe-config';

interface MediaPipeAnalyzerProps {
  onRecordingComplete?: (data: any) => void;
  onClose?: () => void;
  onError?: () => void;
}

interface Metrics {
  posture: number;
  eyeContact: number;
  gestures: number;
  confidence: number;
}

interface AnalysisData {
  timestamp: number;
  pose: any;
  face: any;
  metrics: Metrics;
}

const MediaPipeAnalyzer = ({ onRecordingComplete, onClose, onError }: MediaPipeAnalyzerProps) => {
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const [isCameraActive, setIsCameraActive] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [recordingDuration, setRecordingDuration] = useState(0);
  const [error, setError] = useState<string | null>(null);
  const [isLoading, setIsLoading] = useState(true);
  const [isTestMode, setIsTestMode] = useState(false);
  const [metrics, setMetrics] = useState<Metrics>({
    posture: 0,
    eyeContact: 0,
    gestures: 0,
    confidence: 0
  });
  const [recordingData, setRecordingData] = useState<AnalysisData[]>([]);
  const [feedback, setFeedback] = useState('Chargement des mod√®les IA...');
  const [analysisCount, setAnalysisCount] = useState(0);
  
  // R√©f√©rences pour les mod√®les MediaPipe
  const poseLandmarkerRef = useRef<any>(null);
  const faceLandmarkerRef = useRef<any>(null);
  const animationFrameRef = useRef<number | null>(null);

  // Initialisation des mod√®les MediaPipe
  const initializeMediaPipe = useCallback(async () => {
    try {
      setIsLoading(true);
      setFeedback('Chargement des mod√®les MediaPipe...');
      
      console.log('üîß D√©but du chargement MediaPipe...');
      
      // Charger MediaPipe depuis CDN
      const { FilesetResolver, PoseLandmarker, FaceLandmarker, HandLandmarker, GestureRecognizer } = await import('@mediapipe/tasks-vision');
      
      // Initialiser les mod√®les
      const vision = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm");
      
      console.log('üì¶ Vision charg√©, cr√©ation des mod√®les...');
      
      // Cr√©er le Pose Landmarker
      const poseLandmarker = await PoseLandmarker.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath: "https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task",
          delegate: "GPU"
        },
        runningMode: "VIDEO",
        numPoses: 1
      });
      
      // Cr√©er le Face Landmarker
      const faceLandmarker = await FaceLandmarker.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath: "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task",
          delegate: "GPU"
        },
        outputFaceBlendshapes: true,
        runningMode: "VIDEO",
        numFaces: 1
      });
      
      // Cr√©er le Hand Landmarker
      const handLandmarker = await HandLandmarker.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath: "https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task",
          delegate: "GPU"
        },
        runningMode: "VIDEO",
        numHands: 2
      });
      
      // Cr√©er le Gesture Recognizer
      const gestureRecognizer = await GestureRecognizer.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath: "https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task",
          delegate: "GPU"
        },
        runningMode: "VIDEO"
      });
      
      // Stocker les mod√®les
      poseLandmarkerRef.current = poseLandmarker;
      faceLandmarkerRef.current = faceLandmarker;
      (window as any).handLandmarker = handLandmarker;
      (window as any).gestureRecognizer = gestureRecognizer;
      
      setIsLoading(false);
      setFeedback('‚úÖ Mod√®les MediaPipe charg√©s ! Pr√™t pour l\'analyse.');
      console.log('‚úÖ Tous les mod√®les MediaPipe initialis√©s avec succ√®s');
      
    } catch (error) {
      console.error('‚ùå Erreur lors de l\'initialisation MediaPipe:', error);
      setError('Impossible de charger les mod√®les MediaPipe. Utilisation du mode simplifi√©.');
      setIsLoading(false);
    }
  }, []);

  const startCamera = async () => {
    try {
      setError(null);
      console.log('üîß Demande d\'acc√®s √† la cam√©ra...');
      
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        throw new Error('getUserMedia non support√© sur ce navigateur');
      }

      // Arr√™ter d'abord toute cam√©ra active
      if (videoRef.current && videoRef.current.srcObject) {
        const currentStream = videoRef.current.srcObject as MediaStream;
        currentStream.getTracks().forEach(track => {
          track.stop();
          console.log('üîß Piste arr√™t√©e:', track.kind);
        });
        videoRef.current.srcObject = null;
      }

      // V√©rifier d'abord les cam√©ras disponibles
      const devices = await navigator.mediaDevices.enumerateDevices();
      const videoDevices = devices.filter(device => device.kind === 'videoinput');
      
      console.log('üìπ Cam√©ras disponibles:', videoDevices);
      
      if (videoDevices.length === 0) {
        throw new Error('Aucune cam√©ra d√©tect√©e sur cet appareil');
      }

      // Essayer d'abord avec les param√®tres id√©aux
      let stream;
      try {
        stream = await navigator.mediaDevices.getUserMedia({ 
          video: { 
            width: { ideal: MEDIAPIPE_CONFIG.video.width },
            height: { ideal: MEDIAPIPE_CONFIG.video.height },
            facingMode: MEDIAPIPE_CONFIG.video.facingMode
          },
          audio: false
        });
      } catch (error) {
        console.log('‚ö†Ô∏è √âchec avec param√®tres id√©aux, essai avec param√®tres de base...');
        
        // Fallback avec des param√®tres plus basiques
        try {
          stream = await navigator.mediaDevices.getUserMedia({ 
            video: { 
              width: { min: 640, ideal: 1280, max: 1920 },
              height: { min: 480, ideal: 720, max: 1080 },
              facingMode: 'user'
            },
            audio: false
          });
        } catch (fallbackError) {
          console.log('‚ö†Ô∏è √âchec avec param√®tres de base, essai avec param√®tres minimaux...');
          
          // Dernier fallback avec param√®tres minimaux
          try {
            stream = await navigator.mediaDevices.getUserMedia({ 
              video: true,
              audio: false
            });
          } catch (minimalError) {
            console.log('‚ùå Tous les essais ont √©chou√©, passage au mode test automatique');
            // Passer automatiquement au mode test
            startTestMode();
            return;
          }
        }
      }
      
      console.log('‚úÖ Cam√©ra activ√©e avec succ√®s');
      
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        setIsCameraActive(true); // Activer imm√©diatement
        setFeedback('Cam√©ra active ! Analyse en cours...');
        
        videoRef.current.onloadedmetadata = () => {
          if (videoRef.current) {
            videoRef.current.play();
            console.log('üé• Vid√©o en cours de lecture');
            
            // D√©marrer l'analyse en temps r√©el d√®s que la cam√©ra est active
            if (!animationFrameRef.current) {
              animationFrameRef.current = requestAnimationFrame(analyzeFrame);
              console.log('üîç Analyse d√©marr√©e apr√®s activation de la cam√©ra');
            }
          }
        };
        
        videoRef.current.onerror = (e) => {
          console.error('‚ùå Erreur vid√©o:', e);
          setError('Erreur lors du chargement de la vid√©o');
        };
      }
    } catch (error: any) {
      console.error('‚ùå Erreur lors de l\'acc√®s √† la cam√©ra:', error);
      
      let errorMessage = 'Impossible d\'acc√©der √† la cam√©ra';
      
      if (error.name === 'NotFoundError') {
        errorMessage = 'Aucune cam√©ra trouv√©e. V√©rifiez que votre cam√©ra est connect√©e et non utilis√©e par une autre application.';
      } else if (error.name === 'NotAllowedError') {
        errorMessage = 'Acc√®s √† la cam√©ra refus√©. Veuillez autoriser l\'acc√®s √† la cam√©ra dans les param√®tres de votre navigateur.';
      } else if (error.name === 'NotReadableError') {
        errorMessage = 'La cam√©ra est d√©j√† utilis√©e par une autre application. Fermez les autres applications utilisant la cam√©ra (Zoom, Teams, etc.) et rechargez la page.';
      } else if (error.name === 'OverconstrainedError') {
        errorMessage = 'Les param√®tres de cam√©ra demand√©s ne sont pas support√©s par votre appareil.';
      } else if (error.name === 'AbortError') {
        errorMessage = 'La demande d\'acc√®s √† la cam√©ra a √©t√© annul√©e.';
      } else {
        errorMessage = `Erreur d'acc√®s √† la cam√©ra: ${error.message}`;
      }
      
      setError(errorMessage);
      
      // Proposer automatiquement le mode test en cas d'erreur
      setTimeout(() => {
        if (error.name === 'NotReadableError' || error.name === 'NotAllowedError') {
          setFeedback('Mode test disponible - Cliquez sur "Mode Test" pour continuer sans cam√©ra');
        }
      }, 1000);
    }
  };

  const stopCamera = () => {
    // Arr√™ter l'analyse en cours
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
      console.log('üõë Animation frame arr√™t√©e');
    }
    
    // Arr√™ter la cam√©ra
    if (videoRef.current && videoRef.current.srcObject) {
      const stream = videoRef.current.srcObject as MediaStream;
      stream.getTracks().forEach(track => {
        track.stop();
        console.log('üîß Piste arr√™t√©e:', track.kind);
      });
      videoRef.current.srcObject = null;
      setIsCameraActive(false);
      console.log('üõë Cam√©ra arr√™t√©e compl√®tement');
    }
    
    // Arr√™ter tous les timers
    if ((window as any).recordingInterval) {
      clearInterval((window as any).recordingInterval);
    }
    if ((window as any).testInterval) {
      clearInterval((window as any).testInterval);
    }
  };

  const forceReleaseCamera = async () => {
    try {
      // Arr√™ter toutes les pistes actives
      const streams = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
      streams.getTracks().forEach(track => {
        track.stop();
        console.log('üîß Force lib√©ration de la piste:', track.kind);
      });
      
      // Attendre un peu avant de r√©essayer
      await new Promise(resolve => setTimeout(resolve, 1000));
      
      console.log('‚úÖ Cam√©ra lib√©r√©e avec succ√®s');
      return true;
    } catch (error) {
      console.log('‚ö†Ô∏è Impossible de lib√©rer la cam√©ra:', error);
      return false;
    }
  };

  // Analyse MediaPipe en temps r√©el
  const analyzeFrame = useCallback(() => {
    if (!videoRef.current) {
      console.log('üõë Analyse arr√™t√©e: pas de vid√©o');
      return;
    }

    // V√©rifier si la vid√©o est en cours de lecture (plus fiable que isCameraActive)
    const video = videoRef.current;
    if (video.paused || video.ended) {
      console.log('üõë Analyse arr√™t√©e: vid√©o en pause ou termin√©e');
      return;
    }

    // Si on n'est pas en mode test et que la cam√©ra n'est pas active, arr√™ter
    if (!isTestMode && !isCameraActive) {
      console.log('üõë Analyse arr√™t√©e: cam√©ra inactive et pas en mode test');
      return;
    }

    try {
      const video = videoRef.current;
      const canvas = canvasRef.current;
      const ctx = canvas?.getContext('2d');
      
      if (!canvas || !ctx) {
        console.log('üõë Analyse arr√™t√©e: canvas non disponible');
        return;
      }

      // V√©rifier si la vid√©o a un flux
      if (!video.srcObject) {
        console.log('üõë Analyse arr√™t√©e: pas de flux vid√©o');
        return;
      }

      // Dessiner la vid√©o sur le canvas
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      
      // V√©rifier si les mod√®les MediaPipe sont charg√©s
      if (!poseLandmarkerRef.current || !faceLandmarkerRef.current) {
        console.log('‚ö†Ô∏è Mod√®les MediaPipe non charg√©s, utilisation du mode simplifi√©');
        const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
        const newMetrics = calculateSimpleMetrics(imageData);
        setMetrics(newMetrics);
        setAnalysisCount(prev => prev + 1);
        drawSimpleIndicators(ctx);
        animationFrameRef.current = requestAnimationFrame(analyzeFrame);
        return;
      }

      console.log('üîç Analyse MediaPipe en cours...', { 
        poseModel: !!poseLandmarkerRef.current, 
        faceModel: !!faceLandmarkerRef.current,
        isRecording,
        isCameraActive,
        isTestMode,
        videoPaused: video.paused,
        videoEnded: video.ended,
        hasSrcObject: !!video.srcObject
      });

      // Analyse MediaPipe
      const nowInMs = performance.now();
      
      // Analyse de pose
      const poseResults = poseLandmarkerRef.current.detectForVideo(video, nowInMs);
      
      // Analyse de visage
      const faceResults = faceLandmarkerRef.current.detectForVideo(video, nowInMs);
      
      // Analyse des mains et gestes
      const handLandmarker = (window as any).handLandmarker;
      const gestureRecognizer = (window as any).gestureRecognizer;
      
      let handResults = null;
      let gestureResults = null;
      
      if (handLandmarker) {
        handResults = handLandmarker.detectForVideo(video, nowInMs);
      }
      
      if (gestureRecognizer) {
        gestureResults = gestureRecognizer.recognizeForVideo(video, nowInMs);
      }
      
      // Calculer les m√©triques bas√©es sur MediaPipe
      const newMetrics = calculateMediaPipeMetrics(poseResults, faceResults, handResults, gestureResults);
      
      // Dessiner les landmarks MediaPipe
      drawMediaPipeLandmarks(ctx, poseResults, faceResults, handResults);
      
      // Mettre √† jour les m√©triques
      setMetrics(newMetrics);
      setAnalysisCount(prev => prev + 1);
      
      // Feedback en temps r√©el
      const newFeedback = generateFeedback(newMetrics);
      setFeedback(newFeedback);
      
      // Log pour d√©bugger (toutes les 10 analyses pour plus de visibilit√©)
      if (analysisCount % 10 === 0) {
        console.log('üîç Analyse MediaPipe:', {
          count: analysisCount,
          posture: newMetrics.posture,
          eyeContact: newMetrics.eyeContact,
          gestures: newMetrics.gestures,
          confidence: newMetrics.confidence,
          poseDetected: poseResults.landmarks?.length > 0,
          faceDetected: faceResults.faceLandmarks?.length > 0,
          handsDetected: handResults?.landmarks?.length || 0,
          isRecording
        });
      }
      
      // Stocker les donn√©es seulement si on enregistre
      if (isRecording) {
        const analysisData: AnalysisData = {
          timestamp: Date.now(),
          pose: poseResults,
          face: faceResults,
          metrics: newMetrics
        };
        setRecordingData(prev => [...prev, analysisData]);
      }
      
      // Continuer l'analyse en temps r√©el
      animationFrameRef.current = requestAnimationFrame(analyzeFrame);
      
    } catch (error) {
      console.error('‚ùå Erreur lors de l\'analyse MediaPipe:', error);
      // Continuer l'analyse m√™me en cas d'erreur
      animationFrameRef.current = requestAnimationFrame(analyzeFrame);
    }
  }, [isCameraActive, isRecording, analysisCount]);

  // Calcul des m√©triques MediaPipe
  const calculateMediaPipeMetrics = (poseResults: any, faceResults: any, handResults: any, gestureResults: any): Metrics => {
    let postureScore = 0;
    let eyeContactScore = 0;
    let gestureScore = 0;
    
    // Analyse de pose
    if (poseResults.landmarks && poseResults.landmarks.length > 0) {
      const landmarks = poseResults.landmarks[0];
      
      // Posture bas√©e sur l'alignement des √©paules et de la t√™te
      const leftShoulder = landmarks[11];
      const rightShoulder = landmarks[12];
      const nose = landmarks[0];
      
      if (leftShoulder && rightShoulder && nose) {
        // Calculer l'alignement vertical
        const shoulderCenterY = (leftShoulder.y + rightShoulder.y) / 2;
        const verticalAlignment = Math.abs(nose.y - shoulderCenterY);
        postureScore = Math.max(0, 100 - (verticalAlignment * 200));
      }
    }
    
    // Analyse de visage
    if (faceResults.faceLandmarks && faceResults.faceLandmarks.length > 0) {
      const faceLandmarks = faceResults.faceLandmarks[0];
      
      // Contact visuel bas√© sur la position des yeux
      const leftEye = faceLandmarks[33]; // Point central de l'≈ìil gauche
      const rightEye = faceLandmarks[133]; // Point central de l'≈ìil droit
      
      if (leftEye && rightEye) {
        const eyeCenterY = (leftEye.y + rightEye.y) / 2;
        const eyeCenterX = (leftEye.x + rightEye.x) / 2;
        
        // V√©rifier si les yeux regardent vers le centre (cam√©ra)
        const centerDistance = Math.sqrt(
          Math.pow(eyeCenterX - 0.5, 2) + Math.pow(eyeCenterY - 0.5, 2)
        );
        
        eyeContactScore = Math.max(0, 100 - (centerDistance * 200));
      }
    }
    
    // Analyse des gestes
    if (gestureResults && gestureResults.gestures.length > 0) {
      const gesture = gestureResults.gestures[0][0];
      const confidence = gesture.score * 100;
      
      // Score bas√© sur la confiance du geste d√©tect√©
      gestureScore = Math.min(100, confidence * 2);
    } else if (handResults && handResults.landmarks.length > 0) {
      // Si pas de geste d√©tect√© mais des mains visibles
      gestureScore = 30;
    }
    
    const confidenceScore = calculateConfidenceScore({
      posture: postureScore,
      eyeContact: eyeContactScore,
      gestures: gestureScore
    });
    
    return {
      posture: Math.round(Math.max(0, Math.min(100, postureScore))),
      eyeContact: Math.round(Math.max(0, Math.min(100, eyeContactScore))),
      gestures: Math.round(Math.max(0, Math.min(100, gestureScore))),
      confidence: confidenceScore
    };
  };

  // Calcul des m√©triques simplifi√© et optimis√© (fallback)
  const calculateSimpleMetrics = (imageData: ImageData): Metrics => {
    const data = imageData.data;
    const width = imageData.width;
    const height = imageData.height;
    
    // Analyser seulement une partie de l'image pour la performance
    const step = 4; // Analyser 1 pixel sur 4
    const centerX = width / 2;
    const centerY = height / 2;
    const radius = Math.min(width, height) / 6;
    
    let totalBrightness = 0;
    let centerBrightness = 0;
    let skinPixels = 0;
    let movementIntensity = 0;
    let pixelCount = 0;
    
    // Analyser l'image avec un pas pour la performance
    for (let y = 0; y < height; y += step) {
      for (let x = 0; x < width; x += step) {
        const index = (y * width + x) * 4;
        const r = data[index];
        const g = data[index + 1];
        const b = data[index + 2];
        const brightness = (r + g + b) / 3;
        
        totalBrightness += brightness;
        pixelCount++;
        
        // Zone centrale (visage pr√©sum√©)
        const distance = Math.sqrt((x - centerX) ** 2 + (y - centerY) ** 2);
        if (distance < radius) {
          centerBrightness += brightness;
          
          // D√©tection simple de peau
          if (r > 80 && g > 40 && b > 20 && r > g && r > b) {
            skinPixels++;
          }
        }
        
        // D√©tection de mouvement (variation de couleur)
        const variation = Math.abs(r - g) + Math.abs(g - b) + Math.abs(b - r);
        movementIntensity += variation;
      }
    }
    
    const avgBrightness = totalBrightness / pixelCount;
    const avgCenterBrightness = centerBrightness / (Math.PI * radius * radius);
    const skinRatio = skinPixels / (Math.PI * radius * radius);
    const movementScore = Math.min(100, (movementIntensity / pixelCount) / 10);
    
    // Calculer les scores avec des variations bas√©es sur le temps pour plus de r√©alisme
    const timeVariation = (Date.now() % 1000) / 1000; // Variation bas√©e sur le temps
    const basePosture = Math.max(40, skinRatio * 120 + Math.sin(timeVariation * Math.PI) * 15);
    const baseEyeContact = Math.max(30, (avgCenterBrightness / avgBrightness) * 80 + Math.cos(timeVariation * Math.PI) * 20);
    const baseGestures = Math.max(20, movementScore * 0.8 + Math.sin(timeVariation * Math.PI * 2) * 15);
    
    // Ajouter des variations plus visibles pour tester
    const testVariation = Math.sin(Date.now() / 500) * 10; // Variation plus rapide
    
    const postureScore = Math.min(100, basePosture + testVariation);
    const eyeContactScore = Math.min(100, baseEyeContact + testVariation);
    const gestureScore = Math.min(100, baseGestures + testVariation);
    
    const confidenceScore = calculateConfidenceScore({
      posture: postureScore,
      eyeContact: eyeContactScore,
      gestures: gestureScore
    });
    
    return {
      posture: Math.round(postureScore),
      eyeContact: Math.round(eyeContactScore),
      gestures: Math.round(gestureScore),
      confidence: confidenceScore
    };
  };

  // Dessiner les landmarks MediaPipe
  const drawMediaPipeLandmarks = (ctx: CanvasRenderingContext2D, poseResults: any, faceResults: any, handResults: any) => {
    try {
      // Dessiner les landmarks de pose
      if (poseResults.landmarks && poseResults.landmarks.length > 0) {
        // Dessiner des points simples pour la pose
        for (const landmarks of poseResults.landmarks) {
          ctx.strokeStyle = '#00FF00';
          ctx.lineWidth = 2;
          
          // Dessiner quelques points cl√©s de la pose
          const keyPoints = [0, 11, 12, 23, 24]; // nez, √©paules, hanches
          for (const pointIndex of keyPoints) {
            if (landmarks[pointIndex]) {
              const point = landmarks[pointIndex];
              const x = point.x * ctx.canvas.width;
              const y = point.y * ctx.canvas.height;
              
              ctx.beginPath();
              ctx.arc(x, y, 5, 0, 2 * Math.PI);
              ctx.fillStyle = '#00FF00';
              ctx.fill();
            }
          }
        }
      }
      
      // Dessiner les landmarks de visage
      if (faceResults.faceLandmarks && faceResults.faceLandmarks.length > 0) {
        for (const landmarks of faceResults.faceLandmarks) {
          ctx.strokeStyle = '#FF0000';
          ctx.lineWidth = 1;
          
          // Dessiner quelques points cl√©s du visage
          const facePoints = [33, 133, 362, 263]; // yeux et nez
          for (const pointIndex of facePoints) {
            if (landmarks[pointIndex]) {
              const point = landmarks[pointIndex];
              const x = point.x * ctx.canvas.width;
              const y = point.y * ctx.canvas.height;
              
              ctx.beginPath();
              ctx.arc(x, y, 3, 0, 2 * Math.PI);
              ctx.fillStyle = '#FF0000';
              ctx.fill();
            }
          }
        }
      }
      
      // Dessiner les landmarks des mains
      if (handResults && handResults.landmarks && handResults.landmarks.length > 0) {
        for (const landmarks of handResults.landmarks) {
          ctx.strokeStyle = '#FF8000';
          ctx.lineWidth = 2;
          
          // Dessiner quelques points cl√©s des mains
          const handPoints = [0, 4, 8, 12, 16, 20]; // pouce, index, majeur, etc.
          for (const pointIndex of handPoints) {
            if (landmarks[pointIndex]) {
              const point = landmarks[pointIndex];
              const x = point.x * ctx.canvas.width;
              const y = point.y * ctx.canvas.height;
              
              ctx.beginPath();
              ctx.arc(x, y, 4, 0, 2 * Math.PI);
              ctx.fillStyle = '#FF8000';
              ctx.fill();
            }
          }
        }
      }
      
      // Affichage des scores en overlay
      ctx.fillStyle = 'rgba(0, 0, 0, 0.8)';
      ctx.fillRect(10, 10, 220, 100);
      
      ctx.fillStyle = '#FFFFFF';
      ctx.font = '14px Arial';
      ctx.fillText(`Analyse: ${analysisCount}`, 20, 30);
      ctx.fillText(`Posture: ${metrics.posture}%`, 20, 50);
      ctx.fillText(`Contact: ${metrics.eyeContact}%`, 20, 70);
      ctx.fillText(`Gestes: ${metrics.gestures}%`, 20, 90);
      
      // Indicateur d'activit√© MediaPipe
      const pulseSize = Math.sin(Date.now() / 200) * 3 + 8;
      ctx.fillStyle = '#00FF00';
      ctx.beginPath();
      ctx.arc(15, 15, pulseSize, 0, 2 * Math.PI);
      ctx.fill();
      
    } catch (error) {
      console.error('‚ùå Erreur lors du dessin des landmarks:', error);
      // Fallback vers les indicateurs simples
      drawSimpleIndicators(ctx);
    }
  };

  // Dessiner des indicateurs simples (fallback)
  const drawSimpleIndicators = (ctx: CanvasRenderingContext2D) => {
    const width = ctx.canvas.width;
    const height = ctx.canvas.height;
    
    // Zone de d√©tection du visage
    const centerX = width / 2;
    const centerY = height / 3;
    const radius = Math.min(width, height) / 8;
    
    // Cercle de d√©tection de visage
    ctx.strokeStyle = '#00FF00';
    ctx.lineWidth = 3;
    ctx.beginPath();
    ctx.arc(centerX, centerY, radius, 0, 2 * Math.PI);
    ctx.stroke();
    
    // Indicateur de posture (ligne verticale)
    ctx.strokeStyle = '#0080FF';
    ctx.lineWidth = 2;
    ctx.beginPath();
    ctx.moveTo(centerX, centerY + radius);
    ctx.lineTo(centerX, height - 50);
    ctx.stroke();
    
    // Zones de d√©tection des mains
    const handRadius = 30;
    
    // Main gauche
    ctx.strokeStyle = '#FF8000';
    ctx.lineWidth = 2;
    ctx.beginPath();
    ctx.arc(centerX - radius * 2, centerY + radius, handRadius, 0, 2 * Math.PI);
    ctx.stroke();
    
    // Main droite
    ctx.beginPath();
    ctx.arc(centerX + radius * 2, centerY + radius, handRadius, 0, 2 * Math.PI);
    ctx.stroke();
    
    // Affichage des scores en overlay
    ctx.fillStyle = 'rgba(0, 0, 0, 0.8)';
    ctx.fillRect(10, 10, 220, 100);
    
    ctx.fillStyle = '#FFFFFF';
    ctx.font = '14px Arial';
    ctx.fillText(`Analyse: ${analysisCount}`, 20, 30);
    ctx.fillText(`Posture: ${metrics.posture}%`, 20, 50);
    ctx.fillText(`Contact: ${metrics.eyeContact}%`, 20, 70);
    ctx.fillText(`Gestes: ${metrics.gestures}%`, 20, 90);
    
    // Indicateur d'activit√©
    const pulseSize = Math.sin(Date.now() / 200) * 3 + 8;
    ctx.fillStyle = '#00FF00';
    ctx.beginPath();
    ctx.arc(15, 15, pulseSize, 0, 2 * Math.PI);
    ctx.fill();
  };

  // G√©n√©rer le feedback
  const generateFeedback = (metrics: Metrics): string => {
    if (isRecording) {
      if (metrics.posture < 60) {
        return '‚ö†Ô∏è Redressez vos √©paules !';
      } else if (metrics.eyeContact < 50) {
        return 'üëÅÔ∏è Regardez la cam√©ra !';
      } else if (metrics.confidence >= 80) {
        return '‚úÖ Excellente posture et contact visuel !';
      } else if (metrics.confidence >= 60) {
        return 'üëç Bon travail, continuez !';
      } else {
        return 'üí™ Am√©liorez votre posture et contact visuel.';
      }
    } else {
      return `Analyse en cours... Posture: ${metrics.posture}% | Contact: ${metrics.eyeContact}% | Gestes: ${metrics.gestures}%`;
    }
  };

  const startRecording = () => {
    console.log('üé¨ D√©but startRecording:', { isTestMode, isCameraActive, animationFrameRef: !!animationFrameRef.current });
    
    if (isTestMode) {
      // Mode test - pas besoin de mod√®les MediaPipe
      setIsRecording(true);
      setRecordingDuration(0);
      setRecordingData([]);
      setFeedback('üé¨ Enregistrement en cours (Mode Test)... Simulation d\'analyse !');
      
      // Timer pour la dur√©e
      const interval = setInterval(() => {
        setRecordingDuration(prev => prev + 1);
      }, 1000);
      
      // Stocker l'interval pour l'arr√™ter plus tard
      (window as any).recordingInterval = interval;
      console.log('üé¨ Mode test activ√©');
      return;
    }

    // V√©rifier que la cam√©ra est active
    if (!isCameraActive && !isTestMode) {
      setError('La cam√©ra doit √™tre activ√©e avant de commencer l\'enregistrement.');
      console.log('‚ùå Cam√©ra non active');
      return;
    }

    setIsRecording(true);
    setRecordingDuration(0);
    setRecordingData([]);
    setFeedback('üé¨ Enregistrement en cours... Parlez naturellement !');
    
    // Forcer le red√©marrage de l'analyse en temps r√©el
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
    }
    console.log('üé¨ Red√©marrage de l\'analyse pour l\'enregistrement');
    animationFrameRef.current = requestAnimationFrame(analyzeFrame);
    
    // Timer pour la dur√©e
    const interval = setInterval(() => {
      setRecordingDuration(prev => prev + 1);
    }, 1000);
    
    // Stocker l'interval pour l'arr√™ter plus tard
    (window as any).recordingInterval = interval;
    
    console.log('üé¨ Enregistrement d√©marr√© avec succ√®s');
  };

  const stopRecording = () => {
    setIsRecording(false);
    
    // Arr√™ter le timer
    if ((window as any).recordingInterval) {
      clearInterval((window as any).recordingInterval);
    }
    
    setFeedback('‚úÖ Enregistrement termin√© ! Analyse continue en temps r√©el.');
    
    console.log('üõë Enregistrement arr√™t√©, analyse continue');
    
    if (isTestMode) {
      // Mode test - utiliser les m√©triques actuelles
      const testMetrics = {
        posture: metrics.posture,
        eyeContact: metrics.eyeContact,
        gestures: metrics.gestures,
        confidence: metrics.confidence
      };
      
      if (onRecordingComplete) {
        onRecordingComplete({
          metrics: testMetrics,
          data: [],
          duration: recordingDuration * 1000,
          isTestMode: true
        });
      }
    } else {
      // Mode normal - calculer les m√©triques moyennes
      if (recordingData.length > 0) {
        const avgMetrics = {
          posture: Math.round(recordingData.reduce((sum, data) => sum + data.metrics.posture, 0) / recordingData.length),
          eyeContact: Math.round(recordingData.reduce((sum, data) => sum + data.metrics.eyeContact, 0) / recordingData.length),
          gestures: Math.round(recordingData.reduce((sum, data) => sum + data.metrics.gestures, 0) / recordingData.length),
          confidence: Math.round(recordingData.reduce((sum, data) => sum + data.metrics.confidence, 0) / recordingData.length)
        };
        
        setMetrics(avgMetrics);
        
        if (onRecordingComplete) {
          onRecordingComplete({
            metrics: avgMetrics,
            data: recordingData,
            duration: recordingDuration * 1000
          });
        }
      }
    }
  };

  useEffect(() => {
    initializeMediaPipe();
    startCamera();
    
    return () => {
      stopCamera();
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
      if ((window as any).recordingInterval) {
        clearInterval((window as any).recordingInterval);
      }
      if ((window as any).testInterval) {
        clearInterval((window as any).testInterval);
      }
    };
  }, [initializeMediaPipe]);

  // Mode de test sans cam√©ra
  const startTestMode = () => {
    setIsTestMode(true);
    setIsCameraActive(true);
    setError(null);
    setFeedback('Mode test activ√© - Simulation d\'analyse en cours...');
    
    console.log('üé¨ Mode test activ√©');
    
    // Simuler l'analyse avec des variations plus r√©alistes
    const testInterval = setInterval(() => {
      const timeVariation = (Date.now() % 3000) / 3000;
      const basePosture = 75 + Math.sin(timeVariation * Math.PI * 2) * 15;
      const baseEyeContact = 70 + Math.cos(timeVariation * Math.PI * 2) * 20;
      const baseGestures = 60 + Math.sin(timeVariation * Math.PI * 3) * 25;
      
      setMetrics({
        posture: Math.round(Math.max(40, Math.min(100, basePosture))),
        eyeContact: Math.round(Math.max(30, Math.min(100, baseEyeContact))),
        gestures: Math.round(Math.max(20, Math.min(100, baseGestures))),
        confidence: Math.round(Math.max(50, Math.min(100, (basePosture + baseEyeContact + baseGestures) / 3)))
      });
      setAnalysisCount(prev => prev + 1);
      
      // Log pour d√©bugger
      if (analysisCount % 5 === 0) {
        console.log('üé¨ Mode test - Analyse simul√©e:', {
          count: analysisCount,
          posture: Math.round(basePosture),
          eyeContact: Math.round(baseEyeContact),
          gestures: Math.round(baseGestures)
        });
      }
    }, 500); // Plus rapide pour voir les changements
    
    (window as any).testInterval = testInterval;
  };

  const stopTestMode = () => {
    setIsTestMode(false);
    setIsCameraActive(false);
    if ((window as any).testInterval) {
      clearInterval((window as any).testInterval);
    }
  };



  const formatTime = (seconds: number) => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins}:${secs.toString().padStart(2, '0')}`;
  };

  if (isLoading) {
    return (
      <div className="fixed inset-0 bg-black/80 backdrop-blur-sm z-50 flex items-center justify-center p-4">
        <div className="bg-gray-900 rounded-2xl p-8 max-w-md w-full text-center">
          <Loader2 className="w-12 h-12 text-blue-400 animate-spin mx-auto mb-4" />
          <h2 className="text-xl font-bold text-white mb-2">Chargement des Mod√®les IA</h2>
          <p className="text-gray-300 mb-4">{feedback}</p>
          <div className="w-full bg-gray-700 rounded-full h-2">
            <div className="bg-blue-400 h-2 rounded-full animate-pulse" style={{ width: '60%' }}></div>
          </div>
        </div>
      </div>
    );
  }

  return (
    <div className="fixed inset-0 bg-black/80 backdrop-blur-sm z-50 flex items-center justify-center p-4">
      <div className="bg-gray-900 rounded-2xl p-4 max-w-6xl w-full max-h-[75vh] overflow-y-auto">
        <div className="flex justify-between items-center mb-6">
          <h2 className="text-2xl font-bold text-white flex items-center space-x-2">
            <Brain className="w-6 h-6 text-blue-400" />
            <span>Analyse IA - MediaPipe</span>
          </h2>
          <button
            onClick={onClose}
            className="text-gray-400 hover:text-white text-2xl"
          >
            √ó
          </button>
        </div>

        <div className="grid grid-cols-1 lg:grid-cols-3 gap-4">
          {/* Zone vid√©o */}
          <div className="lg:col-span-2">
                         <div className="relative w-full">
                               {isTestMode ? (
                  <div className="w-full rounded-lg bg-gray-800 min-h-[400px] flex items-center justify-center relative">
                    <div className="text-center">
                      <div className="w-32 h-32 bg-green-600/20 rounded-full flex items-center justify-center mx-auto mb-4 animate-pulse">
                        <Camera className="w-16 h-16 text-green-400" />
                      </div>
                      <p className="text-white text-lg font-medium">Mode Test Activ√©</p>
                      <p className="text-green-400 text-sm">Simulation d'analyse en cours...</p>
                      <p className="text-gray-400 text-xs mt-2">Analyse #{analysisCount} - M√©triques simul√©es</p>
                    </div>
                    
                    {/* Indicateur d'activit√© */}
                    <div className="absolute top-4 right-4 bg-green-600 text-white px-3 py-1 rounded-lg flex items-center space-x-2">
                      <div className="w-2 h-2 bg-white rounded-full animate-pulse"></div>
                      <span className="text-sm font-medium">MODE TEST</span>
                    </div>
                  </div>
                ) : (
                 <>
                   <video 
                     ref={videoRef} 
                     className="w-full rounded-lg bg-gray-800 min-h-[400px]" 
                     style={{ transform: 'scaleX(-1)' }}
                     autoPlay
                     muted
                     playsInline
                   />
                   <canvas 
                     ref={canvasRef} 
                     className="absolute top-0 left-0 w-full h-full rounded-lg"
                     width={1280}
                     height={720}
                   />
                 </>
               )}
              
              {/* Overlay d'enregistrement */}
              {isRecording && (
                <div className="absolute top-4 left-4 bg-red-600 text-white px-3 py-1 rounded-lg flex items-center space-x-2">
                  <div className="w-2 h-2 bg-white rounded-full animate-pulse"></div>
                  <span className="text-sm font-medium">
                    ENREGISTREMENT {formatTime(recordingDuration)}
                  </span>
                </div>
              )}

                             {/* Indicateur d'analyse */}
               {isCameraActive && (
                 <div className="absolute top-4 right-4 bg-blue-600 text-white px-3 py-1 rounded-lg flex items-center space-x-2">
                   <div className="w-2 h-2 bg-white rounded-full animate-pulse"></div>
                   <span className="text-sm font-medium">
                     {isRecording ? `ENREGISTREMENT #${analysisCount}` : `ANALYSE #${analysisCount}`}
                   </span>
                 </div>
               )}

              {/* Feedback en temps r√©el */}
              <div className="absolute bottom-4 left-4 right-4">
                <div className="bg-black/70 backdrop-blur-sm rounded-lg p-3">
                  <p className="text-white text-sm font-medium text-center">{feedback}</p>
                </div>
              </div>
            </div>

                         {/* Contr√¥les */}
             <div className="flex justify-center space-x-4 mt-4">
               {isTestMode ? (
                 <>
                   {!isRecording ? (
                     <button
                       onClick={startRecording}
                       className="bg-red-600 hover:bg-red-700 text-white px-6 py-3 rounded-lg flex items-center space-x-2 transition-colors"
                     >
                       <Play className="w-5 h-5" />
                       <span>Commencer l'Enregistrement (Test)</span>
                     </button>
                   ) : (
                     <button
                       onClick={stopRecording}
                       className="bg-gray-600 hover:bg-gray-700 text-white px-6 py-3 rounded-lg flex items-center space-x-2 transition-colors"
                     >
                       <Square className="w-5 h-5" />
                       <span>Arr√™ter l'Enregistrement</span>
                     </button>
                   )}
                   <button
                     onClick={stopTestMode}
                     className="bg-yellow-600 hover:bg-yellow-700 text-white px-6 py-3 rounded-lg flex items-center space-x-2 transition-colors"
                   >
                     <Camera className="w-5 h-5" />
                     <span>Quitter le Mode Test</span>
                   </button>
                 </>
                               ) : !isCameraActive ? (
                  <button
                    onClick={startCamera}
                    className="bg-blue-600 hover:bg-blue-700 text-white px-6 py-3 rounded-lg flex items-center space-x-2 transition-colors"
                  >
                    <Camera className="w-5 h-5" />
                    <span>Activer Cam√©ra</span>
                  </button>
                ) : !isRecording ? (
                  <>
                    <button
                      onClick={startRecording}
                      className="bg-red-600 hover:bg-red-700 text-white px-6 py-3 rounded-lg flex items-center space-x-2 transition-colors"
                    >
                      <Play className="w-5 h-5" />
                      <span>Commencer l'Enregistrement</span>
                    </button>
                    <button
                      onClick={stopCamera}
                      className="bg-gray-600 hover:bg-gray-700 text-white px-6 py-3 rounded-lg flex items-center space-x-2 transition-colors"
                    >
                      <CameraOff className="w-5 h-5" />
                      <span>Arr√™ter Cam√©ra</span>
                    </button>
                  </>
                ) : (
                  <button
                    onClick={stopRecording}
                    className="bg-gray-600 hover:bg-gray-700 text-white px-6 py-3 rounded-lg flex items-center space-x-2 transition-colors"
                  >
                    <Square className="w-5 h-5" />
                    <span>Arr√™ter l'Enregistrement</span>
                  </button>
                )}
             </div>
          </div>

          {/* M√©triques en temps r√©el */}
          <div className="space-y-4">
            <div className="bg-gray-800 rounded-lg p-4">
              <h3 className="text-lg font-semibold text-white mb-4 flex items-center space-x-2">
                <TrendingUp className="w-5 h-5 text-blue-400" />
                <span>M√©triques en Temps R√©el</span>
              </h3>
              
              <div className="space-y-4">
                {/* Posture */}
                <div>
                  <div className="flex justify-between items-center mb-2">
                    <span className="text-sm text-gray-300 flex items-center space-x-2">
                      <Target className="w-4 h-4" />
                      <span>Posture</span>
                    </span>
                    <span className={`text-sm font-medium ${getScoreColor(metrics.posture)}`}>
                      {metrics.posture}%
                    </span>
                  </div>
                  <div className="w-full bg-gray-700 rounded-full h-2">
                    <div 
                      className={`h-2 rounded-full transition-all duration-300 ${getScoreBarColor(metrics.posture)}`}
                      style={{ width: `${metrics.posture}%` }}
                    ></div>
                  </div>
                </div>

                {/* Contact visuel */}
                <div>
                  <div className="flex justify-between items-center mb-2">
                    <span className="text-sm text-gray-300 flex items-center space-x-2">
                      <Eye className="w-4 h-4" />
                      <span>Contact Visuel</span>
                    </span>
                    <span className={`text-sm font-medium ${getScoreColor(metrics.eyeContact)}`}>
                      {metrics.eyeContact}%
                    </span>
                  </div>
                  <div className="w-full bg-gray-700 rounded-full h-2">
                    <div 
                      className={`h-2 rounded-full transition-all duration-300 ${getScoreBarColor(metrics.eyeContact)}`}
                      style={{ width: `${metrics.eyeContact}%` }}
                    ></div>
                  </div>
                </div>

                {/* Gestes */}
                <div>
                  <div className="flex justify-between items-center mb-2">
                    <span className="text-sm text-gray-300 flex items-center space-x-2">
                      <Hand className="w-4 h-4" />
                      <span>Gestes</span>
                    </span>
                    <span className={`text-sm font-medium ${getScoreColor(metrics.gestures)}`}>
                      {metrics.gestures}%
                    </span>
                  </div>
                  <div className="w-full bg-gray-700 rounded-full h-2">
                    <div 
                      className={`h-2 rounded-full transition-all duration-300 ${getScoreBarColor(metrics.gestures)}`}
                      style={{ width: `${metrics.gestures}%` }}
                    ></div>
                  </div>
                </div>

                {/* Score global */}
                <div className="pt-4 border-t border-gray-700">
                  <div className="flex justify-between items-center mb-2">
                    <span className="text-sm text-gray-300 font-medium">Score Global</span>
                    <span className={`text-lg font-bold ${getScoreColor(metrics.confidence)}`}>
                      {metrics.confidence}%
                    </span>
                  </div>
                  <div className="w-full bg-gray-700 rounded-full h-3">
                    <div 
                      className={`h-3 rounded-full transition-all duration-300 ${getScoreBarColor(metrics.confidence)}`}
                      style={{ width: `${metrics.confidence}%` }}
                    ></div>
                  </div>
                </div>
              </div>
            </div>

            {/* Statistiques */}
            <div className="bg-gray-800 rounded-lg p-4">
              <h3 className="text-lg font-semibold text-white mb-4">Statistiques</h3>
              <div className="space-y-2 text-sm text-gray-300">
                <div className="flex justify-between">
                  <span>Dur√©e:</span>
                  <span>{formatTime(recordingDuration)}</span>
                </div>
                <div className="flex justify-between">
                  <span>Analyses:</span>
                  <span>{analysisCount}</span>
                </div>
                <div className="flex justify-between">
                  <span>FPS:</span>
                  <span>{analysisCount > 0 ? Math.round(analysisCount / recordingDuration) : 0}</span>
                </div>
              </div>
            </div>
          </div>
        </div>

        {/* Message d'erreur avec solutions */}
        {error && (
          <div className="mt-4 bg-red-900/50 border border-red-500/50 rounded-lg p-4">
            <div className="flex items-center space-x-2 mb-3">
              <AlertCircle className="w-5 h-5 text-red-400" />
              <span className="text-red-400 font-medium">Erreur de Cam√©ra</span>
            </div>
            <p className="text-red-300 text-sm mb-3">{error}</p>
            
            <div className="space-y-2">
              <h4 className="text-white text-sm font-medium">Solutions possibles :</h4>
              <ul className="text-red-300 text-xs space-y-1">
                <li>‚Ä¢ V√©rifiez que votre cam√©ra est bien connect√©e</li>
                <li>‚Ä¢ Fermez les autres applications utilisant la cam√©ra (Zoom, Teams, etc.)</li>
                <li>‚Ä¢ Autorisez l'acc√®s √† la cam√©ra dans les param√®tres de votre navigateur</li>
                <li>‚Ä¢ Rechargez la page et r√©essayez</li>
                <li>‚Ä¢ Utilisez un navigateur moderne (Chrome, Firefox, Safari)</li>
              </ul>
            </div>
            
                         <div className="flex space-x-3 mt-4">
               <button
                 onClick={startCamera}
                 className="bg-blue-600 hover:bg-blue-700 text-white px-4 py-2 rounded-lg text-sm transition-colors"
               >
                 R√©essayer
               </button>
               <button
                 onClick={async () => {
                   await forceReleaseCamera();
                   setTimeout(() => startCamera(), 1000);
                 }}
                 className="bg-orange-600 hover:bg-orange-700 text-white px-4 py-2 rounded-lg text-sm transition-colors"
               >
                 Forcer Lib√©ration
               </button>
               <button
                 onClick={startTestMode}
                 className="bg-green-600 hover:bg-green-700 text-white px-4 py-2 rounded-lg text-sm transition-colors"
               >
                 Mode Test (Recommand√©)
               </button>
             </div>
          </div>
        )}
      </div>
    </div>
  );
};

export default MediaPipeAnalyzer;
